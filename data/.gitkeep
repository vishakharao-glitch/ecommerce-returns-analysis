{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b69e45e4-9867-4b76-a0e4-0536a4484b8b",
   "metadata": {},
   "source": [
    "# 📦 E-Commerce Performance & Returns Optimization  \n",
    "An end-to-end analytics project using Python, SQL, and Power BI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f3c86-de2d-4c7d-9db9-945f83b8ec54",
   "metadata": {},
   "source": [
    "## 📂 Data Loading  \n",
    "Importing libraries and reading Excel sheets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0da25220-42bf-4a4c-b956-185f03c286ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load Excel sheets\n",
    "orders_df = pd.read_excel(\"ECOMM DATA.xlsx\", sheet_name=\"Orders\")\n",
    "returns_df = pd.read_excel(\"ECOMM DATA.xlsx\", sheet_name=\"Returns\")\n",
    "people_df = pd.read_excel(\"ECOMM DATA.xlsx\", sheet_name=\"People\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d30ed47-1573-4646-bd1d-c1bca89dde67",
   "metadata": {},
   "source": [
    "## 🧼 Data Cleaning  \n",
    "Convert date columns and check data structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf549c6b-be07-48ac-b9c4-ea1234f6ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df['Order Date'] = pd.to_datetime(orders_df['Order Date'])\n",
    "orders_df['Ship Date'] = pd.to_datetime(orders_df['Ship Date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de18197f-e516-485c-a486-94b62e712542",
   "metadata": {},
   "source": [
    "## 🧪 Feature Engineering  \n",
    "Create new columns for analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15613f7a-613f-45ac-874e-09058cc591a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shipping Duration\n",
    "orders_df['Shipping Duration'] = (orders_df['Ship Date'] - orders_df['Order Date']).dt.days\n",
    "\n",
    "# Returned Flag\n",
    "orders_df['Returned'] = orders_df['Order ID'].isin(returns_df['Order ID'])\n",
    "\n",
    "# Profit Margin\n",
    "orders_df['Profit Margin'] = orders_df['Profit'] / orders_df['Sales']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e1879-a310-4b88-8a03-cbe70ec68025",
   "metadata": {},
   "source": [
    "## 🧼 Data Quality Checks  \n",
    "Handle missing values and duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c246c53-3ba0-4ee7-aa3d-25b42120cbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " Row ID                   0\n",
      "Order ID                 0\n",
      "Order Date               0\n",
      "Ship Date                0\n",
      "Ship Mode                0\n",
      "Customer ID              0\n",
      "Customer Name            0\n",
      "Segment                  0\n",
      "City                     0\n",
      "State                    0\n",
      "Country                  0\n",
      "Postal Code          41296\n",
      "Market                   0\n",
      "Region                   0\n",
      "Product ID               0\n",
      "Category                 0\n",
      "Sub-Category             0\n",
      "Product Name             0\n",
      "Sales                    0\n",
      "Quantity                 0\n",
      "Discount                 0\n",
      "Profit                   0\n",
      "Shipping Cost            0\n",
      "Order Priority           0\n",
      "Shipping Duration        0\n",
      "Returned                 0\n",
      "Profit Margin            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\\n\", orders_df.isnull().sum())\n",
    "\n",
    "# Drop duplicates\n",
    "orders_df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7507c73d-1d12-48b0-b5c9-028403b7f226",
   "metadata": {},
   "source": [
    "## 📊 Exploratory Data Analysis  \n",
    "Basic metrics and grouped insights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c11e8421-fc14-45b4-ba07-c035ba22aa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sales: 12642501.90988\n",
      "Total Profit: 1467457.29128\n",
      "Return Rate: 0.059465782803665435\n",
      "Category\n",
      "Furniture          285204.72380\n",
      "Office Supplies    518473.83430\n",
      "Technology         663778.73318\n",
      "Name: Profit, dtype: float64\n",
      "Region\n",
      "Africa            7.837732e+05\n",
      "Canada            6.692817e+04\n",
      "Caribbean         3.242809e+05\n",
      "Central           2.822303e+06\n",
      "Central Asia      7.528266e+05\n",
      "EMEA              8.061613e+05\n",
      "East              6.787812e+05\n",
      "North             1.248166e+06\n",
      "North Asia        8.483098e+05\n",
      "Oceania           1.100185e+06\n",
      "South             1.600907e+06\n",
      "Southeast Asia    8.844232e+05\n",
      "West              7.254578e+05\n",
      "Name: Sales, dtype: float64\n",
      "Discount-Profit Correlation: -0.3164901718272714\n"
     ]
    }
   ],
   "source": [
    "# Total Sales & Profit\n",
    "print(\"Total Sales:\", orders_df['Sales'].sum())\n",
    "print(\"Total Profit:\", orders_df['Profit'].sum())\n",
    "\n",
    "# Return Rate\n",
    "print(\"Return Rate:\", orders_df['Returned'].mean())\n",
    "\n",
    "# Profit by Category\n",
    "print(orders_df.groupby('Category')['Profit'].sum())\n",
    "\n",
    "# Sales by Region\n",
    "print(orders_df.groupby('Region')['Sales'].sum())\n",
    "\n",
    "# Discount vs Profit Correlation\n",
    "print(\"Discount-Profit Correlation:\", orders_df['Discount'].corr(orders_df['Profit']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad108cd-f733-44fd-8a3a-e9c890d20427",
   "metadata": {},
   "source": [
    "## 💾 Data Export  \n",
    "Save cleaned dataset for SQL and Power BI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61c7327e-7c98-41de-999a-3c62a67f53f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df.to_csv(\"cleaned_orders.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b50b87-d503-4f55-b307-b65e10d05291",
   "metadata": {},
   "source": [
    "## 🧰 Reusable Function  \n",
    "Wrap cleaning steps into a function for reuse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b873280-010b-4e26-9542-cc829bdc9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_orders_data(file_path):\n",
    "    df = pd.read_excel(file_path, sheet_name=\"Orders\")\n",
    "    returns = pd.read_excel(file_path, sheet_name=\"Returns\")\n",
    "    df['Order Date'] = pd.to_datetime(df['Order Date'])\n",
    "    df['Ship Date'] = pd.to_datetime(df['Ship Date'])\n",
    "    df['Shipping Duration'] = (df['Ship Date'] - df['Order Date']).dt.days\n",
    "    df['Returned'] = df['Order ID'].isin(returns['Order ID'])\n",
    "    df['Profit Margin'] = df['Profit'] / df['Sales']\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa69417b-cf2b-467f-9013-7256d021d714",
   "metadata": {},
   "source": [
    "## 📁 Next Steps  \n",
    "\n",
    "This notebook completes the Python phase of the project, including data cleaning, feature engineering, and exploratory analysis. The next stages will focus on deeper business logic and visualization:\n",
    "\n",
    "- 🧠 **SQL Analysis**: Write queries to extract insights such as top-performing categories, return impact, and regional trends.\n",
    "- 📊 **Power BI Dashboard**: Build interactive visuals with KPIs, slicers, and filters to showcase performance and returns.\n",
    "\n",
    "> 📌 *Note: Visualizations for this project are created in Power BI to highlight dynamic filtering and business storytelling.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2148063-c2e3-4c72-b0b8-7e0e3d63533a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.2)\n",
      "Collecting sqlalchemy\n",
      "  Downloading sqlalchemy-2.0.43-cp313-cp313-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting psycopg2\n",
      "  Downloading psycopg2-2.9.10-cp313-cp313-win_amd64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Collecting greenlet>=1 (from sqlalchemy)\n",
      "  Downloading greenlet-3.2.4-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy) (4.15.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading sqlalchemy-2.0.43-cp313-cp313-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.1 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.1 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 3.7 MB/s  0:00:00\n",
      "Downloading psycopg2-2.9.10-cp313-cp313-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 1.0/2.6 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.8/2.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.4/2.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 3.4 MB/s  0:00:00\n",
      "Downloading greenlet-3.2.4-cp313-cp313-win_amd64.whl (299 kB)\n",
      "Installing collected packages: psycopg2, greenlet, sqlalchemy\n",
      "\n",
      "   ---------------------------------------- 0/3 [psycopg2]\n",
      "   ------------- -------------------------- 1/3 [greenlet]\n",
      "   ------------- -------------------------- 1/3 [greenlet]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   ---------------------------------------- 3/3 [sqlalchemy]\n",
      "\n",
      "Successfully installed greenlet-3.2.4 psycopg2-2.9.10 sqlalchemy-2.0.43\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas sqlalchemy psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb18915c-2f5e-4190-bfb8-e753a629d233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data successfully imported into PostgreSQL!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "df = pd.read_csv('C:/Users/hp/OneDrive/Desktop/FOR_PORTFOLIO/cleaned_orders.csv')\n",
    "\n",
    "username = 'postgres'\n",
    "password = 'password'\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "database = 'ecomm_analysis'\n",
    "\n",
    "engine = create_engine(f'postgresql://{username}:{password}@{host}:{port}/{database}')\n",
    "df.to_sql('orders', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"✅ Data successfully imported into PostgreSQL!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212b8dc9-69c3-45ce-8ee9-ffbfa119a0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
